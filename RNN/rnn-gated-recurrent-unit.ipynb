{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "453dd429",
   "metadata": {
    "papermill": {
     "duration": 0.017992,
     "end_time": "2023-12-04T20:03:32.711711",
     "exception": false,
     "start_time": "2023-12-04T20:03:32.693719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is the 4th notebook of the neural networks introduction series. In this notebook, we will implement a gated recurrent unit (GRU) in Pytorch and use it to train a model for stock price prediction. This tutorial covers:\n",
    "\n",
    "- What is a GRU?\n",
    "- Why was GRU introduced?\n",
    "- When to choose GRU over LSTM?\n",
    "- Applications of GRU\n",
    "- How does a GRU work?\n",
    "- Implementation of a time series forecaster using GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ecbe9",
   "metadata": {
    "papermill": {
     "duration": 0.01664,
     "end_time": "2023-12-04T20:03:32.745244",
     "exception": false,
     "start_time": "2023-12-04T20:03:32.728604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://namra.ir/static/kaggle/gru-all.png\" height=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047bebc",
   "metadata": {
    "papermill": {
     "duration": 0.017178,
     "end_time": "2023-12-04T20:03:32.779812",
     "exception": false,
     "start_time": "2023-12-04T20:03:32.762634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What is a GRU?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2545b173",
   "metadata": {
    "papermill": {
     "duration": 0.016707,
     "end_time": "2023-12-04T20:03:32.813499",
     "exception": false,
     "start_time": "2023-12-04T20:03:32.796792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align:justify\">Gated Recurrent Unit (GRU) is a type of neural network architecture that was introduced after the Long Short-Term Memory (LSTM) network. Both GRU and LSTM are variations of recurrent neural networks (RNNs) designed to address the vanishing gradient problem, which can occur when training traditional RNNs on long sequences of data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7064ff5",
   "metadata": {
    "papermill": {
     "duration": 0.016508,
     "end_time": "2023-12-04T20:03:32.847353",
     "exception": false,
     "start_time": "2023-12-04T20:03:32.830845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Why was GRU introduced?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c026c",
   "metadata": {
    "papermill": {
     "duration": 0.016552,
     "end_time": "2023-12-04T20:03:32.880568",
     "exception": false,
     "start_time": "2023-12-04T20:03:32.864016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align:justify\">The GRU was proposed by Kyunghyun Cho, et al. in a paper titled \"Learning to Forget: Continual Prediction with LSTM\" in 2014. The authors introduced the GRU as a simplified version of the LSTM with comparable performance. GRUs have fewer parameters than LSTMs and lack certain components like the memory cell, making them computationally more efficient in some cases.<br><br>\n",
    "LSTMs were introduced earlier by Sepp Hochreiter and Jürgen Schmidhuber in 1997, with the paper titled \"Long Short-Term Memory.\" LSTMs and GRUs are both popular choices for modeling sequential data in deep learning, and the choice between them often depends on the specific task and dataset.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2bdf6",
   "metadata": {
    "papermill": {
     "duration": 0.016428,
     "end_time": "2023-12-04T20:03:32.913556",
     "exception": false,
     "start_time": "2023-12-04T20:03:32.897128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# When to choose GRU over LSTM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3028e04",
   "metadata": {
    "papermill": {
     "duration": 0.016179,
     "end_time": "2023-12-04T20:03:32.946047",
     "exception": false,
     "start_time": "2023-12-04T20:03:32.929868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align:justify\">\n",
    "Choosing between Gated Recurrent Units (GRUs) and Long Short-Term Memory (LSTM) networks often depends on the specific characteristics of the task at hand, as well as considerations related to computational resources and model complexity. Here are some guidelines on when you might choose GRU over LSTM:\n",
    "<br>\n",
    "<ul>\n",
    "\n",
    "<li>Computational Efficiency:</li>\n",
    "\n",
    "GRUs typically have fewer parameters compared to LSTMs, making them computationally more efficient. If you are working with limited computational resources, GRUs might be a more suitable choice.\n",
    "\n",
    "<li>Simplicity:</li>\n",
    "\n",
    "GRUs have a simpler architecture than LSTMs because they lack an explicit memory cell. If your task doesn't require complex memory management and you want a simpler model, GRUs might be preferable.\n",
    "\n",
    "<li>Data Size:</li>\n",
    "\n",
    "If you have a relatively small dataset, GRUs might be a better choice. LSTMs tend to perform better than GRUs on larger datasets where the ability to capture long-term dependencies becomes more crucial.\n",
    "\n",
    "<li>Overfitting:</li>\n",
    "\n",
    "LSTMs, with their more complex structure, might be more prone to overfitting, especially when dealing with smaller datasets. GRUs, being simpler, might be less prone to overfitting in such scenarios.\n",
    "\n",
    "<li>Real-time Applications:</li>\n",
    "\n",
    "GRUs are often considered more suitable for real-time applications due to their lower computational requirements. If your application has strict real-time constraints, a GRU might be a better fit.\n",
    "\n",
    "<li>Task-specific Performance:</li>\n",
    "\n",
    "In practice, the choice between GRU and LSTM may also depend on empirical performance on the specific task you're working on. It's a good idea to experiment with both architectures and evaluate their performance on your dataset.\n",
    "\n",
    "<li>Interpretability:</li>\n",
    "\n",
    "If interpretability is a significant concern, GRUs might be easier to interpret since they have a simpler structure. LSTMs, with their memory cell and gates, may introduce additional complexity in understanding how information is processed over time.\n",
    "</ul>\n",
    "\n",
    "Ultimately, the choice between GRU and LSTM should involve empirical experimentation and validation on your specific task and dataset. It's common to try both architectures and select the one that performs better for your particular use case.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a409f",
   "metadata": {
    "papermill": {
     "duration": 0.016434,
     "end_time": "2023-12-04T20:03:32.978901",
     "exception": false,
     "start_time": "2023-12-04T20:03:32.962467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Applications of GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a023bd",
   "metadata": {
    "papermill": {
     "duration": 0.016309,
     "end_time": "2023-12-04T20:03:33.011551",
     "exception": false,
     "start_time": "2023-12-04T20:03:32.995242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Gated Recurrent Units (GRUs) are widely used in various applications due to their ability to capture sequential dependencies in data. Here are some applications of GRU neural networks, along with references to relevant papers:\n",
    "\n",
    "1. **Natural Language Processing (NLP):**\n",
    "   - GRUs are frequently used for tasks in NLP, such as language modeling, machine translation, and sentiment analysis.\n",
    "   - **Reference:** Cho, K., Van Merriënboer, B., Bahdanau, D., & Bengio, Y. (2014). On the properties of neural machine translation: Encoder-decoder approaches. *arXiv preprint arXiv:1409.1259*.\n",
    "   \n",
    "\n",
    "2. **Speech Recognition:**\n",
    "   - GRUs are employed in speech recognition systems to model sequential patterns in audio signals.\n",
    "   - **Reference:** Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. *arXiv preprint arXiv:1409.0473*.\n",
    "\n",
    "3. **Time Series Prediction:**\n",
    "   - GRUs are used for time series prediction tasks, where the goal is to forecast future values based on historical data.\n",
    "   - **Reference:** Chung, J., Gulcehre, C., Cho, K., & Bengio, Y. (2014). Empirical evaluation of gated recurrent neural networks on sequence modeling. *arXiv preprint arXiv:1412.3555*.\n",
    "\n",
    "4. **Healthcare:**\n",
    "   - GRUs find applications in healthcare for tasks such as patient monitoring, disease prediction, and analysis of medical records.\n",
    "   - **Reference:** Choi, E., Bahadori, M. T., Schuetz, A., Stewart, W. F., & Sun, J. (2016). Doctor AI: Predicting clinical events via recurrent neural networks. *arXiv preprint arXiv:1511.05942*.\n",
    "\n",
    "5. **Gesture Recognition:**\n",
    "   - GRUs are utilized in gesture recognition systems to model and understand sequential patterns in gesture data.\n",
    "   - **Reference:** Fragkiadaki, K., Levine, S., Felsen, P., & Malik, J. (2015). Recurrent network models for human dynamics. In *Proceedings of the IEEE International Conference on Computer Vision (ICCV)*.\n",
    "\n",
    "6. **Video Analysis:**\n",
    "   - GRUs are applied in video analysis tasks, including action recognition and video captioning.\n",
    "   - **Reference:** Donahue, J., Anne Hendricks, L., Guadarrama, S., Rohrbach, M., Venugopalan, S., Saenko, K., & Darrell, T. (2015). Long-term recurrent convolutional networks for visual recognition and description. In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*.\n",
    "\n",
    "7. **Financial Time Series Analysis:**\n",
    "   - GRUs are employed in predicting financial market trends and analyzing time series data in finance.\n",
    "   - **Reference:** Lim, Y. J., Na, J. C., Lee, W. S., Kim, Y. G., & Kim, K. H. (2019). Stock price prediction using LSTM, RNN and GRU neural network. *Sustainability, 11*(18), 4933.\n",
    "\n",
    "These references provide insights into the applications and effectiveness of GRUs in various domains. Keep in mind that the field of deep learning is rapidly evolving, and new papers may emerge with advancements in GRU-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91862d1b",
   "metadata": {
    "papermill": {
     "duration": 0.057238,
     "end_time": "2023-12-04T20:03:33.085036",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.027798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How does a GRU work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e4519",
   "metadata": {
    "papermill": {
     "duration": 0.016291,
     "end_time": "2023-12-04T20:03:33.117978",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.101687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align:justify\">A Gated Recurrent Unit takes as input the previous hidden state and the current input, and outputs the current hidden state. The hidden state is also known as the memory of the network. The GRU has two gates: a reset gate and an update gate. The reset gate determines how to combine the new input with the previous memory, and the update gate defines how much of the previous memory to keep around. We will describe the process of calculating the output in the next cells.</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d128312",
   "metadata": {
    "papermill": {
     "duration": 0.016306,
     "end_time": "2023-12-04T20:03:33.151136",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.134830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reset Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81224cc2",
   "metadata": {
    "papermill": {
     "duration": 0.016327,
     "end_time": "2023-12-04T20:03:33.184277",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.167950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The reset gate $r_t$ determines which parts of the previous hidden state $h_{t-1}$ should be forgotten or reset. It takes a concatenated input of the previous hidden state $h_{t-1}$ and the current input $x_t$, and outputs a number between 0 and 1 for each number in the hidden state $h_{t-1}$. A value of 0 means the corresponding number in the hidden state should be reset to 0, while a value of 1 means the corresponding number in the hidden state should be left unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe599c0",
   "metadata": {
    "papermill": {
     "duration": 0.016249,
     "end_time": "2023-12-04T20:03:33.217465",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.201216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://namra.ir/static/kaggle/reset-gate.png\" height=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb4476",
   "metadata": {
    "papermill": {
     "duration": 0.016656,
     "end_time": "2023-12-04T20:03:33.250553",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.233897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$r_t = \\sigma(W_r[h_{t-1};x_t]+b_r)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059c096",
   "metadata": {
    "papermill": {
     "duration": 0.016438,
     "end_time": "2023-12-04T20:03:33.284901",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.268463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Update Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c085d",
   "metadata": {
    "papermill": {
     "duration": 0.016247,
     "end_time": "2023-12-04T20:03:33.317748",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.301501",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The update gate $z_t$ decides how much of the new candidate hidden state should be blended with the previous hidden state. The input to the update gate is the same as the reset gate, a concatenated input of the previous hidden state $h_{t-1}$ and the current input $x_t$. The output of the update gate is a number between 0 and 1 for each number in the hidden state $h_{t-1}$. A value of 0 means the corresponding number in the hidden state should be completely forgotten, while a value of 1 means the corresponding number in the hidden state should be completely remembered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a506e5ec",
   "metadata": {
    "papermill": {
     "duration": 0.01632,
     "end_time": "2023-12-04T20:03:33.351035",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.334715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://namra.ir/static/kaggle/update-gate.png\" height=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d6e2c8",
   "metadata": {
    "papermill": {
     "duration": 0.016231,
     "end_time": "2023-12-04T20:03:33.383871",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.367640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$z_t = \\sigma(W_z[h_{t-1};x_t]+b_z)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ea238",
   "metadata": {
    "papermill": {
     "duration": 0.016228,
     "end_time": "2023-12-04T20:03:33.416610",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.400382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The effect of the reset gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0036a76",
   "metadata": {
    "papermill": {
     "duration": 0.016241,
     "end_time": "2023-12-04T20:03:33.449211",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.432970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The output of the reset gate $r_t$ is multiplied element-wise with the previous hidden state $h_{t-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c2d93",
   "metadata": {
    "papermill": {
     "duration": 0.016256,
     "end_time": "2023-12-04T20:03:33.482048",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.465792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://namra.ir/static/kaggle/reset-gate-continue.png\" height=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c3405",
   "metadata": {
    "papermill": {
     "duration": 0.01666,
     "end_time": "2023-12-04T20:03:33.515752",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.499092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$r_t \\odot h_{t-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36526b",
   "metadata": {
    "papermill": {
     "duration": 0.016752,
     "end_time": "2023-12-04T20:03:33.549537",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.532785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Candidate Hidden State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3196418",
   "metadata": {
    "papermill": {
     "duration": 0.016304,
     "end_time": "2023-12-04T20:03:33.582497",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.566193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The candidate hidden state $\\tilde{h}_t$ represents the new information that could be added to the hidden state. It is a normalized version of the concatenatation of the previous hidden state $h_{t-1}$ and the current input $x_t$. This normalization is done using the $\\tanh$ function, which squashes the values to be between -1 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38810f47",
   "metadata": {
    "papermill": {
     "duration": 0.016256,
     "end_time": "2023-12-04T20:03:33.615186",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.598930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://namra.ir/static/kaggle/gru-candidate-hidden-state.png\" height=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c9e5be",
   "metadata": {
    "papermill": {
     "duration": 0.016251,
     "end_time": "2023-12-04T20:03:33.648198",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.631947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$\\tilde{h}_t = \\mathrm{TH}(W_h[r_t \\odot h_{t-1};x_t] + b_h)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39022fa9",
   "metadata": {
    "papermill": {
     "duration": 0.016462,
     "end_time": "2023-12-04T20:03:33.681268",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.664806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hidden State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4829a9a",
   "metadata": {
    "papermill": {
     "duration": 0.016721,
     "end_time": "2023-12-04T20:03:33.714506",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.697785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The hidden state at a timestep like $t$ (denoted by $h_t$) is actually the output of the network at that time. To calculate the new hidden state, we should combine the previous hidden state $h_{t-1}$ and the new candidate state using the update gate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1876ec",
   "metadata": {
    "papermill": {
     "duration": 0.016513,
     "end_time": "2023-12-04T20:03:33.747437",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.730924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://namra.ir/static/kaggle/gru-hidden-state.png\" height=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169d7bf",
   "metadata": {
    "papermill": {
     "duration": 0.016263,
     "end_time": "2023-12-04T20:03:33.780447",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.764184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "$$h_t = (1-z_t)\\odot h_{t-1}+z_t \\odot \\tilde{h}_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2572fed",
   "metadata": {
    "papermill": {
     "duration": 0.01653,
     "end_time": "2023-12-04T20:03:33.813598",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.797068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This equation blends the previous hidden state with the new candidate hidden state based on the update gate. If $z_t$ is close to 1, the new information is retained; if $z_t$ is close to 0, more of the previous state is retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f876e1",
   "metadata": {
    "papermill": {
     "duration": 0.01631,
     "end_time": "2023-12-04T20:03:33.846405",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.830095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## All in one intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089c456",
   "metadata": {
    "papermill": {
     "duration": 0.016472,
     "end_time": "2023-12-04T20:03:33.879813",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.863341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://namra.ir/static/kaggle/gru-all.png\" height=300></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb9dc36",
   "metadata": {
    "papermill": {
     "duration": 0.016352,
     "end_time": "2023-12-04T20:03:33.913129",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.896777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- **Reset Gate ($r_t$):** Decides which parts of the previous hidden state to forget. If \\(r_t\\) is close to 1, it means that the model should consider more of the previous hidden state.\n",
    "\n",
    "$$r_t = \\sigma(W_r[h_{t-1};x_t]+b_r)$$\n",
    "\n",
    "- **Update Gate ($z_t$):** Determines how much of the new candidate hidden state should be included in the final hidden state. If \\(z_t\\) is close to 1, the model gives more weight to the new candidate hidden state.\n",
    "\n",
    "$$z_t = \\sigma(W_z[h_{t-1};x_t]+b_z)$$\n",
    "\n",
    "- **Candidate Hidden State ($\\tilde{h}_t$):** Represents the new information that could be added to the hidden state.\n",
    "\n",
    "$$\\tilde{h}_t = \\mathrm{TH}(W_h[r_t \\odot h_{t-1};x_t] + b_h)$$\n",
    "\n",
    "- **Final Hidden State ($h_t$):** The updated hidden state that considers both the previous state and the new information based on the reset and update gates.\n",
    "\n",
    "$$h_t = (1-z_t)\\odot h_{t-1}+z_t \\odot \\tilde{h}_t$$\n",
    "\n",
    "These mechanisms allow GRUs to selectively remember or forget information, enabling them to capture long-term dependencies in sequential data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b59ac",
   "metadata": {
    "papermill": {
     "duration": 0.016266,
     "end_time": "2023-12-04T20:03:33.946071",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.929805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0dc644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:33.980671Z",
     "iopub.status.busy": "2023-12-04T20:03:33.980295Z",
     "iopub.status.idle": "2023-12-04T20:03:33.984870Z",
     "shell.execute_reply": "2023-12-04T20:03:33.984095Z"
    },
    "papermill": {
     "duration": 0.024073,
     "end_time": "2023-12-04T20:03:33.986726",
     "exception": false,
     "start_time": "2023-12-04T20:03:33.962653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "# !pip install spacy\n",
    "# !python3.11 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f9d9b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:34.021379Z",
     "iopub.status.busy": "2023-12-04T20:03:34.021108Z",
     "iopub.status.idle": "2023-12-04T20:03:55.635816Z",
     "shell.execute_reply": "2023-12-04T20:03:55.635030Z"
    },
    "papermill": {
     "duration": 21.634786,
     "end_time": "2023-12-04T20:03:55.638291",
     "exception": false,
     "start_time": "2023-12-04T20:03:34.003505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import gensim\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "880b6e39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:55.674764Z",
     "iopub.status.busy": "2023-12-04T20:03:55.674209Z",
     "iopub.status.idle": "2023-12-04T20:03:55.679082Z",
     "shell.execute_reply": "2023-12-04T20:03:55.678262Z"
    },
    "papermill": {
     "duration": 0.024757,
     "end_time": "2023-12-04T20:03:55.681123",
     "exception": false,
     "start_time": "2023-12-04T20:03:55.656366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path': 'data.csv',\n",
    "    'batch_size': 64,\n",
    "    'device': 'cuda', # mps for mac m1, cuda for gpu-enabled devices\n",
    "    'learning_rate': 0.01,\n",
    "    'num_epochs': 100,\n",
    "    'train_size': 0.8,\n",
    "    'random_seed': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19833bd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:55.715827Z",
     "iopub.status.busy": "2023-12-04T20:03:55.715559Z",
     "iopub.status.idle": "2023-12-04T20:03:55.726092Z",
     "shell.execute_reply": "2023-12-04T20:03:55.725269Z"
    },
    "papermill": {
     "duration": 0.029982,
     "end_time": "2023-12-04T20:03:55.728030",
     "exception": false,
     "start_time": "2023-12-04T20:03:55.698048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7853d9326e50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(config['random_seed'])\n",
    "torch.random.manual_seed(config['random_seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d9a5b",
   "metadata": {
    "papermill": {
     "duration": 0.017431,
     "end_time": "2023-12-04T20:03:55.763000",
     "exception": false,
     "start_time": "2023-12-04T20:03:55.745569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea215b",
   "metadata": {
    "papermill": {
     "duration": 0.016986,
     "end_time": "2023-12-04T20:03:55.797425",
     "exception": false,
     "start_time": "2023-12-04T20:03:55.780439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For this tutorial, we will use the Amazon's stock market data. Basically, we will use the previous days stock market data to predict the next day's closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea2a1a28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:55.833483Z",
     "iopub.status.busy": "2023-12-04T20:03:55.833145Z",
     "iopub.status.idle": "2023-12-04T20:03:59.074878Z",
     "shell.execute_reply": "2023-12-04T20:03:59.073685Z"
    },
    "papermill": {
     "duration": 3.262805,
     "end_time": "2023-12-04T20:03:59.077601",
     "exception": false,
     "start_time": "2023-12-04T20:03:55.814796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-04 20:03:56--  https://www.dropbox.com/scl/fi/5zgutd3y6sm5jwuak60rp/data.csv?rlkey=2mivltwxvmx3rtjfzhltp0e09&dl=1\r\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.83.18, 2620:100:6033:18::a27d:5312\r\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.83.18|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://uc0e53467e8896953b63b2815fe2.dl.dropboxusercontent.com/cd/0/inline/CIzY-cWyevX2Gy_OIIVVyafcddjMx0WUi0zFkmBDKWTlJg6sRQGoEGE8xzZXsY2MnCtaVtapxQiVGzS3MNKYDwe37CSGln5xU5vcRbDwIEqfL5xnyNWge6noFO4Rv3w7Th3bZm5b58ZCYKO7Pd2CQCT4/file?dl=1# [following]\r\n",
      "--2023-12-04 20:03:57--  https://uc0e53467e8896953b63b2815fe2.dl.dropboxusercontent.com/cd/0/inline/CIzY-cWyevX2Gy_OIIVVyafcddjMx0WUi0zFkmBDKWTlJg6sRQGoEGE8xzZXsY2MnCtaVtapxQiVGzS3MNKYDwe37CSGln5xU5vcRbDwIEqfL5xnyNWge6noFO4Rv3w7Th3bZm5b58ZCYKO7Pd2CQCT4/file?dl=1\r\n",
      "Resolving uc0e53467e8896953b63b2815fe2.dl.dropboxusercontent.com (uc0e53467e8896953b63b2815fe2.dl.dropboxusercontent.com)... 162.125.83.15, 2620:100:6033:15::a27d:530f\r\n",
      "Connecting to uc0e53467e8896953b63b2815fe2.dl.dropboxusercontent.com (uc0e53467e8896953b63b2815fe2.dl.dropboxusercontent.com)|162.125.83.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 444858 (434K) [application/binary]\r\n",
      "Saving to: ‘data.csv’\r\n",
      "\r\n",
      "data.csv            100%[===================>] 434.43K   992KB/s    in 0.4s    \r\n",
      "\r\n",
      "2023-12-04 20:03:58 (992 KB/s) - ‘data.csv’ saved [444858/444858]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -O 'data.csv' 'https://www.dropbox.com/scl/fi/5zgutd3y6sm5jwuak60rp/data.csv?rlkey=2mivltwxvmx3rtjfzhltp0e09&dl=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2bbe916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:59.118904Z",
     "iopub.status.busy": "2023-12-04T20:03:59.118558Z",
     "iopub.status.idle": "2023-12-04T20:03:59.166288Z",
     "shell.execute_reply": "2023-12-04T20:03:59.165281Z"
    },
    "papermill": {
     "duration": 0.07249,
     "end_time": "2023-12-04T20:03:59.168755",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.096265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.096354</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>1443120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-05-16</td>\n",
       "      <td>0.098438</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>294000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-05-19</td>\n",
       "      <td>0.088021</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>122136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-20</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>109344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-21</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.082292</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>377064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6511</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>101.550003</td>\n",
       "      <td>103.040001</td>\n",
       "      <td>101.010002</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>53633400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6512</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>102.160004</td>\n",
       "      <td>103.489998</td>\n",
       "      <td>101.949997</td>\n",
       "      <td>103.290001</td>\n",
       "      <td>103.290001</td>\n",
       "      <td>56704300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6513</th>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>102.300003</td>\n",
       "      <td>103.290001</td>\n",
       "      <td>101.430000</td>\n",
       "      <td>102.410004</td>\n",
       "      <td>102.410004</td>\n",
       "      <td>41135700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6514</th>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>102.750000</td>\n",
       "      <td>104.199997</td>\n",
       "      <td>102.110001</td>\n",
       "      <td>103.949997</td>\n",
       "      <td>103.949997</td>\n",
       "      <td>48662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>103.910004</td>\n",
       "      <td>103.910004</td>\n",
       "      <td>100.750000</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>101.099998</td>\n",
       "      <td>45103000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6516 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "0     1997-05-15    0.121875    0.125000    0.096354    0.097917    0.097917   \n",
       "1     1997-05-16    0.098438    0.098958    0.085417    0.086458    0.086458   \n",
       "2     1997-05-19    0.088021    0.088542    0.081250    0.085417    0.085417   \n",
       "3     1997-05-20    0.086458    0.087500    0.081771    0.081771    0.081771   \n",
       "4     1997-05-21    0.081771    0.082292    0.068750    0.071354    0.071354   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "6511  2023-03-30  101.550003  103.040001  101.010002  102.000000  102.000000   \n",
       "6512  2023-03-31  102.160004  103.489998  101.949997  103.290001  103.290001   \n",
       "6513  2023-04-03  102.300003  103.290001  101.430000  102.410004  102.410004   \n",
       "6514  2023-04-04  102.750000  104.199997  102.110001  103.949997  103.949997   \n",
       "6515  2023-04-05  103.910004  103.910004  100.750000  101.099998  101.099998   \n",
       "\n",
       "          Volume  \n",
       "0     1443120000  \n",
       "1      294000000  \n",
       "2      122136000  \n",
       "3      109344000  \n",
       "4      377064000  \n",
       "...          ...  \n",
       "6511    53633400  \n",
       "6512    56704300  \n",
       "6513    41135700  \n",
       "6514    48662500  \n",
       "6515    45103000  \n",
       "\n",
       "[6516 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(config['data_path'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba5d215",
   "metadata": {
    "papermill": {
     "duration": 0.021241,
     "end_time": "2023-12-04T20:03:59.213929",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.192688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f1f8b9",
   "metadata": {
    "papermill": {
     "duration": 0.021522,
     "end_time": "2023-12-04T20:03:59.256915",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.235393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see, the dataset contains the closing price of Amazon's stock market from 1997 to 2023. We will use the past week (7 days) stock market data to predict the next day's closing price. In order to this, we have to transform the dataset in a way that each row of it contains the past 7 days stock market data and the next day's closing price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8514d0d0",
   "metadata": {
    "papermill": {
     "duration": 0.020843,
     "end_time": "2023-12-04T20:03:59.299855",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.279012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First of all, we drop the unnecessary columns (`Open`, `High`, `Low`, `Adj Close`, `Volume`) and then we create a new column called `Target` which contains the next day's closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "015c1e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:59.343580Z",
     "iopub.status.busy": "2023-12-04T20:03:59.342913Z",
     "iopub.status.idle": "2023-12-04T20:03:59.353552Z",
     "shell.execute_reply": "2023-12-04T20:03:59.352718Z"
    },
    "papermill": {
     "duration": 0.035514,
     "end_time": "2023-12-04T20:03:59.356301",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.320787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Open', 'High', 'Low', 'Adj Close', 'Volume'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d232da0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:59.406119Z",
     "iopub.status.busy": "2023-12-04T20:03:59.405774Z",
     "iopub.status.idle": "2023-12-04T20:03:59.418359Z",
     "shell.execute_reply": "2023-12-04T20:03:59.417327Z"
    },
    "papermill": {
     "duration": 0.038639,
     "end_time": "2023-12-04T20:03:59.420691",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.382052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>0.097917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-05-16</td>\n",
       "      <td>0.086458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-05-19</td>\n",
       "      <td>0.085417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-20</td>\n",
       "      <td>0.081771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-21</td>\n",
       "      <td>0.071354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6511</th>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6512</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>103.290001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6513</th>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>102.410004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6514</th>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>103.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>101.099998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6516 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Close\n",
       "0     1997-05-15    0.097917\n",
       "1     1997-05-16    0.086458\n",
       "2     1997-05-19    0.085417\n",
       "3     1997-05-20    0.081771\n",
       "4     1997-05-21    0.071354\n",
       "...          ...         ...\n",
       "6511  2023-03-30  102.000000\n",
       "6512  2023-03-31  103.290001\n",
       "6513  2023-04-03  102.410004\n",
       "6514  2023-04-04  103.949997\n",
       "6515  2023-04-05  101.099998\n",
       "\n",
       "[6516 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad2168",
   "metadata": {
    "papermill": {
     "duration": 0.019208,
     "end_time": "2023-12-04T20:03:59.461623",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.442415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we iterate over the dataset to make our set of features (the closing values corresponding to the past 7 days) and the `target` (the closing value of the next day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e58654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:59.502669Z",
     "iopub.status.busy": "2023-12-04T20:03:59.502275Z",
     "iopub.status.idle": "2023-12-04T20:03:59.507042Z",
     "shell.execute_reply": "2023-12-04T20:03:59.506161Z"
    },
    "papermill": {
     "duration": 0.027723,
     "end_time": "2023-12-04T20:03:59.508983",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.481260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates = df['Date'].values\n",
    "close_prices = df['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b6a0c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:59.549974Z",
     "iopub.status.busy": "2023-12-04T20:03:59.549635Z",
     "iopub.status.idle": "2023-12-04T20:03:59.608006Z",
     "shell.execute_reply": "2023-12-04T20:03:59.607203Z"
    },
    "papermill": {
     "duration": 0.081113,
     "end_time": "2023-12-04T20:03:59.610034",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.528921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for idx, date in enumerate(dates[7:], start=7):\n",
    "    data_dict[date] = {\n",
    "            'target': close_prices[idx],\n",
    "            't-1': close_prices[idx-1],\n",
    "            't-2': close_prices[idx-2],\n",
    "            't-3': close_prices[idx-3],\n",
    "            't-4': close_prices[idx-4],\n",
    "            't-5': close_prices[idx-5],\n",
    "            't-6': close_prices[idx-6],\n",
    "            't-7': close_prices[idx-7],\n",
    "        }\n",
    "df = pd.DataFrame.from_dict(data_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c1bfaa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:59.650155Z",
     "iopub.status.busy": "2023-12-04T20:03:59.649855Z",
     "iopub.status.idle": "2023-12-04T20:03:59.669409Z",
     "shell.execute_reply": "2023-12-04T20:03:59.668499Z"
    },
    "papermill": {
     "duration": 0.041541,
     "end_time": "2023-12-04T20:03:59.671425",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.629884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-05-27</th>\n",
       "      <td>0.097917</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.069792</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.079167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-28</th>\n",
       "      <td>0.086458</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.069792</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.076563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-29</th>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.069792</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.076563</td>\n",
       "      <td>0.075260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-30</th>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.069792</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.076563</td>\n",
       "      <td>0.075260</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-06-02</th>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.069792</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.076563</td>\n",
       "      <td>0.075260</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.075521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30</th>\n",
       "      <td>100.610001</td>\n",
       "      <td>98.699997</td>\n",
       "      <td>98.709999</td>\n",
       "      <td>98.129997</td>\n",
       "      <td>98.040001</td>\n",
       "      <td>97.239998</td>\n",
       "      <td>100.250000</td>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>98.699997</td>\n",
       "      <td>98.709999</td>\n",
       "      <td>98.129997</td>\n",
       "      <td>98.040001</td>\n",
       "      <td>97.239998</td>\n",
       "      <td>100.250000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>103.290001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>98.709999</td>\n",
       "      <td>98.129997</td>\n",
       "      <td>98.040001</td>\n",
       "      <td>97.239998</td>\n",
       "      <td>100.250000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>103.290001</td>\n",
       "      <td>102.410004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04</th>\n",
       "      <td>98.129997</td>\n",
       "      <td>98.040001</td>\n",
       "      <td>97.239998</td>\n",
       "      <td>100.250000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>103.290001</td>\n",
       "      <td>102.410004</td>\n",
       "      <td>103.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-05</th>\n",
       "      <td>98.040001</td>\n",
       "      <td>97.239998</td>\n",
       "      <td>100.250000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>103.290001</td>\n",
       "      <td>102.410004</td>\n",
       "      <td>103.949997</td>\n",
       "      <td>101.099998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6509 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t-7        t-6         t-5         t-4         t-3  \\\n",
       "1997-05-27    0.097917   0.086458    0.085417    0.081771    0.071354   \n",
       "1997-05-28    0.086458   0.085417    0.081771    0.071354    0.069792   \n",
       "1997-05-29    0.085417   0.081771    0.071354    0.069792    0.075000   \n",
       "1997-05-30    0.081771   0.071354    0.069792    0.075000    0.079167   \n",
       "1997-06-02    0.071354   0.069792    0.075000    0.079167    0.076563   \n",
       "...                ...        ...         ...         ...         ...   \n",
       "2023-03-30  100.610001  98.699997   98.709999   98.129997   98.040001   \n",
       "2023-03-31   98.699997  98.709999   98.129997   98.040001   97.239998   \n",
       "2023-04-03   98.709999  98.129997   98.040001   97.239998  100.250000   \n",
       "2023-04-04   98.129997  98.040001   97.239998  100.250000  102.000000   \n",
       "2023-04-05   98.040001  97.239998  100.250000  102.000000  103.290001   \n",
       "\n",
       "                   t-2         t-1      target  \n",
       "1997-05-27    0.069792    0.075000    0.079167  \n",
       "1997-05-28    0.075000    0.079167    0.076563  \n",
       "1997-05-29    0.079167    0.076563    0.075260  \n",
       "1997-05-30    0.076563    0.075260    0.075000  \n",
       "1997-06-02    0.075260    0.075000    0.075521  \n",
       "...                ...         ...         ...  \n",
       "2023-03-30   97.239998  100.250000  102.000000  \n",
       "2023-03-31  100.250000  102.000000  103.290001  \n",
       "2023-04-03  102.000000  103.290001  102.410004  \n",
       "2023-04-04  103.290001  102.410004  103.949997  \n",
       "2023-04-05  102.410004  103.949997  101.099998  \n",
       "\n",
       "[6509 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['t-7', 't-6', 't-5', 't-4', 't-3', 't-2', 't-1', 'target']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c198d3",
   "metadata": {
    "papermill": {
     "duration": 0.019181,
     "end_time": "2023-12-04T20:03:59.710485",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.691304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you see, as we get closer to the recent years, the stock prices are higher. So, we have to normalize the dataset to make the values in the same range. We use the `MinMaxScaler` to normalize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b438bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:59.750619Z",
     "iopub.status.busy": "2023-12-04T20:03:59.750249Z",
     "iopub.status.idle": "2023-12-04T20:03:59.776855Z",
     "shell.execute_reply": "2023-12-04T20:03:59.775895Z"
    },
    "papermill": {
     "duration": 0.049598,
     "end_time": "2023-12-04T20:03:59.779500",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.729902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-05-27</th>\n",
       "      <td>-0.999698</td>\n",
       "      <td>-0.999821</td>\n",
       "      <td>-0.999832</td>\n",
       "      <td>-0.999872</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999955</td>\n",
       "      <td>-0.999911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-28</th>\n",
       "      <td>-0.999821</td>\n",
       "      <td>-0.999832</td>\n",
       "      <td>-0.999872</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999944</td>\n",
       "      <td>-0.999911</td>\n",
       "      <td>-0.999939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-29</th>\n",
       "      <td>-0.999832</td>\n",
       "      <td>-0.999872</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999944</td>\n",
       "      <td>-0.999899</td>\n",
       "      <td>-0.999939</td>\n",
       "      <td>-0.999953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-30</th>\n",
       "      <td>-0.999872</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999944</td>\n",
       "      <td>-0.999899</td>\n",
       "      <td>-0.999927</td>\n",
       "      <td>-0.999953</td>\n",
       "      <td>-0.999955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-06-02</th>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999944</td>\n",
       "      <td>-0.999899</td>\n",
       "      <td>-0.999927</td>\n",
       "      <td>-0.999941</td>\n",
       "      <td>-0.999955</td>\n",
       "      <td>-0.999950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30</th>\n",
       "      <td>0.078175</td>\n",
       "      <td>0.057693</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.051580</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.042036</td>\n",
       "      <td>0.074309</td>\n",
       "      <td>0.093076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>0.057693</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.051580</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.042036</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>0.093076</td>\n",
       "      <td>0.106910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.051580</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.042036</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>0.093081</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>0.097473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04</th>\n",
       "      <td>0.051580</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.042036</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>0.093081</td>\n",
       "      <td>0.106915</td>\n",
       "      <td>0.097473</td>\n",
       "      <td>0.113988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-05</th>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.042036</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>0.093081</td>\n",
       "      <td>0.106915</td>\n",
       "      <td>0.097478</td>\n",
       "      <td>0.113988</td>\n",
       "      <td>0.083425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6509 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t-7       t-6       t-5       t-4       t-3       t-2  \\\n",
       "1997-05-27 -0.999698 -0.999821 -0.999832 -0.999872 -0.999983 -1.000000   \n",
       "1997-05-28 -0.999821 -0.999832 -0.999872 -0.999983 -1.000000 -0.999944   \n",
       "1997-05-29 -0.999832 -0.999872 -0.999983 -1.000000 -0.999944 -0.999899   \n",
       "1997-05-30 -0.999872 -0.999983 -1.000000 -0.999944 -0.999899 -0.999927   \n",
       "1997-06-02 -0.999983 -1.000000 -0.999944 -0.999899 -0.999927 -0.999941   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2023-03-30  0.078175  0.057693  0.057800  0.051580  0.050615  0.042036   \n",
       "2023-03-31  0.057693  0.057800  0.051580  0.050615  0.042036  0.074315   \n",
       "2023-04-03  0.057800  0.051580  0.050615  0.042036  0.074315  0.093081   \n",
       "2023-04-04  0.051580  0.050615  0.042036  0.074315  0.093081  0.106915   \n",
       "2023-04-05  0.050615  0.042036  0.074315  0.093081  0.106915  0.097478   \n",
       "\n",
       "                 t-1    target  \n",
       "1997-05-27 -0.999955 -0.999911  \n",
       "1997-05-28 -0.999911 -0.999939  \n",
       "1997-05-29 -0.999939 -0.999953  \n",
       "1997-05-30 -0.999953 -0.999955  \n",
       "1997-06-02 -0.999955 -0.999950  \n",
       "...              ...       ...  \n",
       "2023-03-30  0.074309  0.093076  \n",
       "2023-03-31  0.093076  0.106910  \n",
       "2023-04-03  0.106910  0.097473  \n",
       "2023-04-04  0.097473  0.113988  \n",
       "2023-04-05  0.113988  0.083425  \n",
       "\n",
       "[6509 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "df[['t-7', 't-6', 't-5', 't-4', 't-3', 't-2', 't-1', 'target']] = scaler.fit_transform(df[['t-7', 't-6', 't-5', 't-4', 't-3', 't-2', 't-1', 'target']])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d9d08",
   "metadata": {
    "papermill": {
     "duration": 0.019904,
     "end_time": "2023-12-04T20:03:59.819388",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.799484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let us consider the closing values of the past 7 days as our features (`x`) and the closing value of the next day as our target (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86607094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:59.859978Z",
     "iopub.status.busy": "2023-12-04T20:03:59.859337Z",
     "iopub.status.idle": "2023-12-04T20:03:59.865460Z",
     "shell.execute_reply": "2023-12-04T20:03:59.864475Z"
    },
    "papermill": {
     "duration": 0.028647,
     "end_time": "2023-12-04T20:03:59.867498",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.838851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df[['t-7', 't-6', 't-5', 't-4', 't-3', 't-2', 't-1']].values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56374bd5",
   "metadata": {
    "papermill": {
     "duration": 0.019971,
     "end_time": "2023-12-04T20:03:59.908327",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.888356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Splitting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034f6916",
   "metadata": {
    "papermill": {
     "duration": 0.020367,
     "end_time": "2023-12-04T20:03:59.948447",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.928080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need to split the dataset into training and testing sets. We will use the first 80% of the dataset as the training set, another 10% as the testing set and the rest as the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "650dbda8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:03:59.990629Z",
     "iopub.status.busy": "2023-12-04T20:03:59.989960Z",
     "iopub.status.idle": "2023-12-04T20:03:59.996698Z",
     "shell.execute_reply": "2023-12-04T20:03:59.995925Z"
    },
    "papermill": {
     "duration": 0.030129,
     "end_time": "2023-12-04T20:03:59.998617",
     "exception": false,
     "start_time": "2023-12-04T20:03:59.968488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_rem, y_train, y_rem = train_test_split(x, y, train_size=config['train_size'], shuffle=True)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_rem, y_rem, train_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a1e98",
   "metadata": {
    "papermill": {
     "duration": 0.020181,
     "end_time": "2023-12-04T20:04:00.039003",
     "exception": false,
     "start_time": "2023-12-04T20:04:00.018822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now is the time to make a Pytorch `Dataset` object out of our data. Since we want the GRU network to take into account the fact that these values have a temporal order, we have to make a sliding window of size 7 over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41cd0b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:00.081777Z",
     "iopub.status.busy": "2023-12-04T20:04:00.081430Z",
     "iopub.status.idle": "2023-12-04T20:04:00.087748Z",
     "shell.execute_reply": "2023-12-04T20:04:00.086767Z"
    },
    "papermill": {
     "duration": 0.030051,
     "end_time": "2023-12-04T20:04:00.089763",
     "exception": false,
     "start_time": "2023-12-04T20:04:00.059712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, values, targets):\n",
    "        self.values = values.reshape(-1, 7, 1)\n",
    "        self.labels = np.array(targets).reshape(-1, 1)\n",
    "    def __len__(self):\n",
    "        return self.values.shape[0]\n",
    "    def __getitem__(self, idx):        \n",
    "        return Tensor(self.values[idx]).to(config['device']), Tensor(self.labels[idx]).to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ad81045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:00.131546Z",
     "iopub.status.busy": "2023-12-04T20:04:00.131248Z",
     "iopub.status.idle": "2023-12-04T20:04:00.135732Z",
     "shell.execute_reply": "2023-12-04T20:04:00.134955Z"
    },
    "papermill": {
     "duration": 0.027433,
     "end_time": "2023-12-04T20:04:00.137585",
     "exception": false,
     "start_time": "2023-12-04T20:04:00.110152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = StockDataset(x_train, y_train)\n",
    "test_dataset = StockDataset(x_test, y_test)\n",
    "val_dataset = StockDataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d40c7",
   "metadata": {
    "papermill": {
     "duration": 0.019644,
     "end_time": "2023-12-04T20:04:00.177101",
     "exception": false,
     "start_time": "2023-12-04T20:04:00.157457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To iterate over the data while training the model, we need to create a `DataLoader` object. We will use the `DataLoader` class to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eceac9c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:00.220095Z",
     "iopub.status.busy": "2023-12-04T20:04:00.219449Z",
     "iopub.status.idle": "2023-12-04T20:04:00.225044Z",
     "shell.execute_reply": "2023-12-04T20:04:00.224177Z"
    },
    "papermill": {
     "duration": 0.028888,
     "end_time": "2023-12-04T20:04:00.226907",
     "exception": false,
     "start_time": "2023-12-04T20:04:00.198019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3011c49",
   "metadata": {
    "papermill": {
     "duration": 0.020804,
     "end_time": "2023-12-04T20:04:00.268043",
     "exception": false,
     "start_time": "2023-12-04T20:04:00.247239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining the Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26988a0",
   "metadata": {
    "papermill": {
     "duration": 0.019485,
     "end_time": "2023-12-04T20:04:00.307351",
     "exception": false,
     "start_time": "2023-12-04T20:04:00.287866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Side Note: The DropOut Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7581b186",
   "metadata": {
    "papermill": {
     "duration": 0.020636,
     "end_time": "2023-12-04T20:04:00.348243",
     "exception": false,
     "start_time": "2023-12-04T20:04:00.327607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A Dropout layer is a regularization technique where we randomly set some of the dimensions of the input vector to 0. This helps in preventing overfitting. The `Dropout` class in Pytorch implements this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6450fcb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:00.391279Z",
     "iopub.status.busy": "2023-12-04T20:04:00.390933Z",
     "iopub.status.idle": "2023-12-04T20:04:00.397541Z",
     "shell.execute_reply": "2023-12-04T20:04:00.396669Z"
    },
    "papermill": {
     "duration": 0.029619,
     "end_time": "2023-12-04T20:04:00.399454",
     "exception": false,
     "start_time": "2023-12-04T20:04:00.369835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.gru = nn.GRU(input_size=1, hidden_size=4, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dense = nn.Linear(4, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output, _ = self.gru(x) # output shape: (batch_size, seq_len, hidden_size)\n",
    "        output = self.dropout(output)\n",
    "        output = self.dense(output[:, -1, :]) # output shape: (batch_size, 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb41cd5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:00.442089Z",
     "iopub.status.busy": "2023-12-04T20:04:00.441270Z",
     "iopub.status.idle": "2023-12-04T20:04:05.170563Z",
     "shell.execute_reply": "2023-12-04T20:04:05.169572Z"
    },
    "papermill": {
     "duration": 4.753424,
     "end_time": "2023-12-04T20:04:05.173010",
     "exception": false,
     "start_time": "2023-12-04T20:04:00.419586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model().to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a369d8c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:05.215075Z",
     "iopub.status.busy": "2023-12-04T20:04:05.214766Z",
     "iopub.status.idle": "2023-12-04T20:04:05.458900Z",
     "shell.execute_reply": "2023-12-04T20:04:05.457980Z"
    },
    "papermill": {
     "duration": 0.267108,
     "end_time": "2023-12-04T20:04:05.460958",
     "exception": false,
     "start_time": "2023-12-04T20:04:05.193850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(32, 7, 1).to(config['device'])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b28f5a",
   "metadata": {
    "papermill": {
     "duration": 0.020149,
     "end_time": "2023-12-04T20:04:05.501704",
     "exception": false,
     "start_time": "2023-12-04T20:04:05.481555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optimization Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bb62dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:05.544206Z",
     "iopub.status.busy": "2023-12-04T20:04:05.543647Z",
     "iopub.status.idle": "2023-12-04T20:04:05.548290Z",
     "shell.execute_reply": "2023-12-04T20:04:05.547493Z"
    },
    "papermill": {
     "duration": 0.027794,
     "end_time": "2023-12-04T20:04:05.550205",
     "exception": false,
     "start_time": "2023-12-04T20:04:05.522411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "186825d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:05.592407Z",
     "iopub.status.busy": "2023-12-04T20:04:05.592133Z",
     "iopub.status.idle": "2023-12-04T20:04:05.596203Z",
     "shell.execute_reply": "2023-12-04T20:04:05.595450Z"
    },
    "papermill": {
     "duration": 0.026907,
     "end_time": "2023-12-04T20:04:05.598029",
     "exception": false,
     "start_time": "2023-12-04T20:04:05.571122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbbb8644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:05.639909Z",
     "iopub.status.busy": "2023-12-04T20:04:05.639392Z",
     "iopub.status.idle": "2023-12-04T20:04:05.648068Z",
     "shell.execute_reply": "2023-12-04T20:04:05.647212Z"
    },
    "papermill": {
     "duration": 0.031845,
     "end_time": "2023-12-04T20:04:05.650015",
     "exception": false,
     "start_time": "2023-12-04T20:04:05.618170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch_num):\n",
    "    num_points = len(dataloader.dataset)\n",
    "    for batch, (features, labels) in enumerate(dataloader):        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(features)\n",
    "        loss = loss_fn(pred, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad() # sets gradients of all model parameters to zero\n",
    "        loss.backward() # calculate the gradients again\n",
    "        optimizer.step() # w = w - learning_rate * grad(loss)_with_respect_to_w\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(features)\n",
    "            print(f\"\\r Epoch {epoch_num} - loss: {loss:>7f}  [{current:>5d}/{num_points:>5d}]\", end=\" \")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, epoch_num, name):\n",
    "    num_points = len(dataloader.dataset)\n",
    "    sum_test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (features, labels) in enumerate(dataloader):\n",
    "            pred = model(features)\n",
    "            sum_test_loss += loss_fn(pred, labels).item() # add the current loss to the sum of the losses\n",
    "            \n",
    "    sum_test_loss /= num_points\n",
    "    print(f\"\\r Epoch {epoch_num} - {name} Avg loss: {sum_test_loss:>8f}\", end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b63df",
   "metadata": {
    "papermill": {
     "duration": 0.020301,
     "end_time": "2023-12-04T20:04:05.690938",
     "exception": false,
     "start_time": "2023-12-04T20:04:05.670637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the Model and Evaluating the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9c7dace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:05.732935Z",
     "iopub.status.busy": "2023-12-04T20:04:05.732642Z",
     "iopub.status.idle": "2023-12-04T20:04:53.379203Z",
     "shell.execute_reply": "2023-12-04T20:04:53.378102Z"
    },
    "papermill": {
     "duration": 47.669751,
     "end_time": "2023-12-04T20:04:53.381242",
     "exception": false,
     "start_time": "2023-12-04T20:04:05.711491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 100 - Development/Validation Avg loss: 0.000235 "
     ]
    }
   ],
   "source": [
    "for epoch_num in range(1, config['num_epochs']+1):\n",
    "    train_loop(train_loader, model, criterion, optimizer, epoch_num)\n",
    "    test_loop(val_loader, model, criterion, epoch_num, 'Development/Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e44c214a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:53.439225Z",
     "iopub.status.busy": "2023-12-04T20:04:53.438886Z",
     "iopub.status.idle": "2023-12-04T20:04:53.486425Z",
     "shell.execute_reply": "2023-12-04T20:04:53.485384Z"
    },
    "papermill": {
     "duration": 0.078601,
     "end_time": "2023-12-04T20:04:53.488479",
     "exception": false,
     "start_time": "2023-12-04T20:04:53.409878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 100 - Test Avg loss: 0.000211 "
     ]
    }
   ],
   "source": [
    "test_loop(test_loader, model, criterion, epoch_num, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca2204",
   "metadata": {
    "papermill": {
     "duration": 0.028366,
     "end_time": "2023-12-04T20:04:53.545645",
     "exception": false,
     "start_time": "2023-12-04T20:04:53.517279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Calculating the coefficient of determination ($R^2$) is a good way to evaluate the performance of a regression model. The coefficient of determination is the proportion of the variance in the dependent variable that is predictable from the independent variable(s). It is a statistic used in the context of statistical models whose main purpose is either the prediction of future outcomes or the testing of hypotheses, on the basis of other related information. It provides a measure of how well observed outcomes are replicated by the model, based on the proportion of total variation of outcomes explained by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "703d66b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:53.606225Z",
     "iopub.status.busy": "2023-12-04T20:04:53.605393Z",
     "iopub.status.idle": "2023-12-04T20:04:53.611473Z",
     "shell.execute_reply": "2023-12-04T20:04:53.610757Z"
    },
    "papermill": {
     "duration": 0.037691,
     "end_time": "2023-12-04T20:04:53.613378",
     "exception": false,
     "start_time": "2023-12-04T20:04:53.575687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model(Tensor(x_test.reshape(-1, 7, 1)).to(config['device'])).cpu().detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e56ddb03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:53.672760Z",
     "iopub.status.busy": "2023-12-04T20:04:53.671992Z",
     "iopub.status.idle": "2023-12-04T20:04:53.676207Z",
     "shell.execute_reply": "2023-12-04T20:04:53.675345Z"
    },
    "papermill": {
     "duration": 0.035931,
     "end_time": "2023-12-04T20:04:53.678146",
     "exception": false,
     "start_time": "2023-12-04T20:04:53.642215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_values = y_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba2d3f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:53.736915Z",
     "iopub.status.busy": "2023-12-04T20:04:53.736103Z",
     "iopub.status.idle": "2023-12-04T20:04:53.743391Z",
     "shell.execute_reply": "2023-12-04T20:04:53.742587Z"
    },
    "papermill": {
     "duration": 0.038516,
     "end_time": "2023-12-04T20:04:53.745215",
     "exception": false,
     "start_time": "2023-12-04T20:04:53.706699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9368562897619723"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(true_values, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd42ea",
   "metadata": {
    "papermill": {
     "duration": 0.028188,
     "end_time": "2023-12-04T20:04:53.801837",
     "exception": false,
     "start_time": "2023-12-04T20:04:53.773649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Future Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8297ee65",
   "metadata": {
    "papermill": {
     "duration": 0.028228,
     "end_time": "2023-12-04T20:04:53.858902",
     "exception": false,
     "start_time": "2023-12-04T20:04:53.830674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that we have calculated the normalized values. In real life, what we need is the actual values. So, we have to inverse the normalization process to get the actual values. In order to do this, we need to somehow store the `scaler` object. We can use the `pickle` module to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c53f6805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:53.918418Z",
     "iopub.status.busy": "2023-12-04T20:04:53.917560Z",
     "iopub.status.idle": "2023-12-04T20:04:53.922694Z",
     "shell.execute_reply": "2023-12-04T20:04:53.921683Z"
    },
    "papermill": {
     "duration": 0.036963,
     "end_time": "2023-12-04T20:04:53.924600",
     "exception": false,
     "start_time": "2023-12-04T20:04:53.887637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pkl.dump(scaler, open('/kaggle/working/scaler', 'wb')) # saving the scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef95b19",
   "metadata": {
    "papermill": {
     "duration": 0.028692,
     "end_time": "2023-12-04T20:04:53.982242",
     "exception": false,
     "start_time": "2023-12-04T20:04:53.953550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have saved the `scaler` object, we are assured that our work was not in vain. We can load the `scaler` object and use it to inverse the normalization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01297b61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:54.041057Z",
     "iopub.status.busy": "2023-12-04T20:04:54.040397Z",
     "iopub.status.idle": "2023-12-04T20:04:54.044968Z",
     "shell.execute_reply": "2023-12-04T20:04:54.044020Z"
    },
    "papermill": {
     "duration": 0.036083,
     "end_time": "2023-12-04T20:04:54.046837",
     "exception": false,
     "start_time": "2023-12-04T20:04:54.010754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = pkl.load(open('/kaggle/working/scaler', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a638df60",
   "metadata": {
    "papermill": {
     "duration": 0.028711,
     "end_time": "2023-12-04T20:04:54.104734",
     "exception": false,
     "start_time": "2023-12-04T20:04:54.076023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There's one more thing we need to do when we inverse the normalization process. We have to concatenate the features and the target so that the shape of the input to the scaler becomes `(1,8)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd1fc059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:54.163589Z",
     "iopub.status.busy": "2023-12-04T20:04:54.162768Z",
     "iopub.status.idle": "2023-12-04T20:04:54.167647Z",
     "shell.execute_reply": "2023-12-04T20:04:54.166774Z"
    },
    "papermill": {
     "duration": 0.036503,
     "end_time": "2023-12-04T20:04:54.169676",
     "exception": false,
     "start_time": "2023-12-04T20:04:54.133173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "concatenated_values = np.concatenate((x_test[0].reshape(1, -1), predictions[0].reshape(1, -1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7690bdaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:54.230118Z",
     "iopub.status.busy": "2023-12-04T20:04:54.229459Z",
     "iopub.status.idle": "2023-12-04T20:04:54.236349Z",
     "shell.execute_reply": "2023-12-04T20:04:54.235482Z"
    },
    "papermill": {
     "duration": 0.039585,
     "end_time": "2023-12-04T20:04:54.238444",
     "exception": false,
     "start_time": "2023-12-04T20:04:54.198859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.728     , 3.71      , 3.806     , 3.823     , 4.1145    ,\n",
       "        4.036     , 3.915     , 0.21925712]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(concatenated_values) # the last value is the predicted value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf38902",
   "metadata": {
    "papermill": {
     "duration": 0.028864,
     "end_time": "2023-12-04T20:04:54.299257",
     "exception": false,
     "start_time": "2023-12-04T20:04:54.270393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What if we get a new value? How do we predict the next day's closing price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d4ec3",
   "metadata": {
    "papermill": {
     "duration": 0.029201,
     "end_time": "2023-12-04T20:04:54.357759",
     "exception": false,
     "start_time": "2023-12-04T20:04:54.328558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, we make an array of shape `(1,8)` by concatenating the last 7 values of the dataset and a zero. Then we normalize the array using the `scaler` object. Now, we can use the model to predict the next day's closing price. The prediction will consist of 8 normalized values in the range of -1 to 1. However, we need the actual value. So, we inverse the normalization process and get the actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a68a33a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:54.417862Z",
     "iopub.status.busy": "2023-12-04T20:04:54.417194Z",
     "iopub.status.idle": "2023-12-04T20:04:54.423853Z",
     "shell.execute_reply": "2023-12-04T20:04:54.422975Z"
    },
    "papermill": {
     "duration": 0.038929,
     "end_time": "2023-12-04T20:04:54.425736",
     "exception": false,
     "start_time": "2023-12-04T20:04:54.386807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_next_day(previous_days):\n",
    "    raw_values = np.concatenate((previous_days, [0]), axis=0).reshape(1, -1)\n",
    "    scaled_values = scaler.transform(raw_values)\n",
    "    scaled_input = scaled_values.squeeze()[:-1].reshape(-1, 7, 1)\n",
    "    output = model(Tensor(scaled_input).to(config['device'])).cpu().detach().numpy()\n",
    "    scaled_values = np.concatenate((previous_days.reshape(1,-1), output), axis=1)\n",
    "    raw_values = scaler.inverse_transform(scaled_values)\n",
    "    prediction = raw_values.squeeze()[-1]\n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9845362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:04:54.485833Z",
     "iopub.status.busy": "2023-12-04T20:04:54.485463Z",
     "iopub.status.idle": "2023-12-04T20:04:54.496467Z",
     "shell.execute_reply": "2023-12-04T20:04:54.495596Z"
    },
    "papermill": {
     "duration": 0.043626,
     "end_time": "2023-12-04T20:04:54.498563",
     "exception": false,
     "start_time": "2023-12-04T20:04:54.454937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.122449053059763"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_day(x_test[0])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 87.569481,
   "end_time": "2023-12-04T20:04:56.944847",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-04T20:03:29.375366",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
